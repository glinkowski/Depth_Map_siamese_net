# The train/test net protocol buffer definition
net: "./depth_train_test.prototxt"
# test_iter specifies how many forward passes the test should carry out.
# Train images: 2128, Test images: 236

# number of test iterations
#	batch 8 * iter 30 = 240
test_iter: 30
# how often to run on test data
test_interval: 300
max_iter: 4800
snapshot: 1200
snapshot_prefix: "snapshots/depth"

#lr_policy: "inv"
#gamma: 0.0001
#power: 0.75
#base_lr: 0.001
#momentum: 0.9
#weight_decay: 0.0005

lr_policy: "step"
stepsize: 1200
base_lr: 0.0005
gamma: 0.2
momentum: 0.9
weight_decay: 0.0005

display: 50

solver_mode: GPU



#### EXAMPLES ####
#
# # In the case of MNIST, we have test batch size 100 and 100 test iterations,
# # covering the full 10,000 testing images.
# test_iter: 100
# # Carry out testing every 500 training iterations.
# test_interval: 500
# # The base learning rate, momentum and the weight decay of the network.
# base_lr: 0.01
# momentum: 0.9
# weight_decay: 0.0000
# # The learning rate policy
# lr_policy: "inv"
# gamma: 0.0001
# power: 0.75
# # Display every 100 iterations
# display: 100
# # The maximum number of iterations
# max_iter: 50000
# # snapshot intermediate results
# snapshot: 5000
# snapshot_prefix: "examples/siamese/mnist_siamese"
# # solver mode: CPU or GPU
# solver_mode: GPU
# 
# net: "models/bvlc_reference_caffenet/train_val.prototxt"
# test_iter: 1000
# test_interval: 1000
# base_lr: 0.01
# lr_policy: "step"
# gamma: 0.1
# stepsize: 100000
# display: 20
# max_iter: 450000
# momentum: 0.9
# weight_decay: 0.0005
# snapshot: 10000
# snapshot_prefix: "models/bvlc_reference_caffenet/caffenet_train"
# solver_mode: GPU