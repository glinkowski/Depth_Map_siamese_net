name: "depth_big_siamese_train_test"


######################################
#### LOAD DATA: 3 training images ####
######################################
layer {
  name: "LTrain_data"
  type: "Data"
  top: "L_data"
  top: "L_junk_label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "lmdb_files/depth_train_L_mean.binaryproto"
  }
  data_param {
    source: "lmdb_files/depth_train_L_lmdb"
    batch_size: 4
    backend: LMDB
  }
}
layer {
  name: "RTrain_data"
  type: "Data"
  top: "R_data"
  top: "R_junk_label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mean_file: "lmdb_files/depth_train_R_mean.binaryproto"
  }
  data_param {
    source: "lmdb_files/depth_train_R_lmdb"
    batch_size: 4
    backend: LMDB
  }
}
layer {
  name: "GTTrain_data"
  type: "Data"
  top: "GT_data"
  top: "GT_junk_label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
#    mean_file: "lmdb_files/depth_train_GT_mean.binaryproto"
  }
  data_param {
    source: "lmdb_files/depth_train_GT_lmdb"
    batch_size: 4
    backend: LMDB
  }
}


######################################
#### LOAD DATA: 3 testing images  ####
######################################
layer {
  name: "LTest_data"
  type: "Data"
  top: "L_data"
  top: "L_junk_label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "lmdb_files/depth_test_L_mean.binaryproto"
  }
  data_param {
    source: "lmdb_files/depth_test_L_lmdb"
    batch_size: 4
    backend: LMDB
  }
}
layer {
  name: "RTest_data"
  type: "Data"
  top: "R_data"
  top: "R_junk_label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mean_file: "lmdb_files/depth_test_R_mean.binaryproto"
  }
  data_param {
    source: "lmdb_files/depth_test_R_lmdb"
    batch_size: 4
    backend: LMDB
  }
}
layer {
  name: "GTTest_data"
  type: "Data"
  top: "GT_data"
  top: "GT_junk_label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
#    mean_file: "lmdb_files/depth_test_GT_mean.binaryproto"
  }
  data_param {
    source: "lmdb_files/depth_test_GT_lmdb"
    batch_size: 4
    backend: LMDB
  }
}


######################################
#### SILENCE OUTPUT: fake labels  ####
######################################
layer {
  name: "stfu_L"
  type: "Silence"
  bottom: "L_junk_label"
}
layer {
  name: "stfu_R"
  type: "Silence"
  bottom: "R_junk_label"
}
layer {
  name: "stfu_GT"
  type: "Silence"
  bottom: "GT_junk_label"
}


######################################
#### STEP 1: initial conv         ####
####     in: 128 x 256            ####
####    out: 64 x 128 x 16        ####
######################################

#### Left Leg  #######################
layer {
  name: "conv1_L"
  type: "Convolution"
  bottom: "L_data"
  top: "conv1_L"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    pad: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_L"
  type: "ReLU"
  bottom: "conv1_L"
  top: "conv1_L"
}
#layer {
#  name: "norm1_L"
#  type: "LRN"
#  bottom: "conv1_L"
#  top: "conv1_L"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "conv1b_L"
  type: "Convolution"
  bottom: "conv1_L"
  top: "conv1b_L"
  param {
    name: "conv1b_w"
    lr_mult: 1
  }
  param {
    name: "conv1b_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1b_L"
  type: "ReLU"
  bottom: "conv1b_L"
  top: "conv1b_L"
}
#layer {
#  name: "norm1b_L"
#  type: "LRN"
#  bottom: "conv1b_L"
#  top: "conv1b_L"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "pool1_L"
  type: "Pooling"
  bottom: "conv1b_L"
#  bottom: "conv1_L"
  top: "pool1_L"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#### Right Leg #######################
layer {
  name: "conv1_R"
  type: "Convolution"
  bottom: "R_data"
  top: "conv1_R"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    pad: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_R"
  type: "ReLU"
  bottom: "conv1_R"
  top: "conv1_R"
}
#layer {
#  name: "norm1_R"
#  type: "LRN"
#  bottom: "conv1_R"
#  top: "conv1_R"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "conv1b_R"
  type: "Convolution"
  bottom: "conv1_R"
  top: "conv1b_R"
  param {
    name: "conv1b_w"
    lr_mult: 1
  }
  param {
    name: "conv1b_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1b_R"
  type: "ReLU"
  bottom: "conv1b_R"
  top: "conv1b_R"
}
#layer {
#  name: "norm1b_R"
#  type: "LRN"
#  bottom: "conv1b_R"
#  top: "conv1b_R"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "pool1_R"
  type: "Pooling"
  bottom: "conv1b_R"
#  bottom: "conv1_R"
  top: "pool1_R"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}


######################################
#### STEP 2: conv set 2           ####
####     in: 64 x 128 x 16        ####
####    out: 32 x 64 x 64         ####
######################################

#### Left Leg  #######################
layer {
  name: "conv2_L"
  type: "Convolution"
  bottom: "pool1_L"
  top: "conv2_L"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_L"
  type: "ReLU"
  bottom: "conv2_L"
  top: "conv2_L"
}
#layer {
#  name: "norm2_L"
#  type: "LRN"
#  bottom: "conv2_L"
#  top: "conv2_L"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "conv2b_L"
  type: "Convolution"
  bottom: "conv2_L"
  top: "conv2b_L"
  param {
    name: "conv2b_w"
    lr_mult: 1
  }
  param {
    name: "conv2b_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2b_L"
  type: "ReLU"
  bottom: "conv2b_L"
  top: "conv2b_L"
}
#layer {
#  name: "norm2b_L"
#  type: "LRN"
#  bottom: "conv2b_L"
#  top: "conv2b_L"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "pool2_L"
  type: "Pooling"
  bottom: "conv2b_L"
#  bottom: "conv2_L"
  top: "pool2_L"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#### Right Leg #######################
layer {
  name: "conv2_R"
  type: "Convolution"
  bottom: "pool1_R"
  top: "conv2_R"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_R"
  type: "ReLU"
  bottom: "conv2_R"
  top: "conv2_R"
}
#layer {
#  name: "norm2_R"
#  type: "LRN"
#  bottom: "conv2_R"
#  top: "conv2_R"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "conv2b_R"
  type: "Convolution"
  bottom: "conv2_R"
  top: "conv2b_R"
  param {
    name: "conv2b_w"
    lr_mult: 1
  }
  param {
    name: "conv2b_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2b_R"
  type: "ReLU"
  bottom: "conv2b_R"
  top: "conv2b_R"
}
#layer {
#  name: "norm2b_R"
#  type: "LRN"
#  bottom: "conv2b_R"
#  top: "conv2b_R"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "pool2_R"
  type: "Pooling"
  bottom: "conv2b_R"
#  bottom: "conv2_R"
  top: "pool2_R"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}


######################################
#### STEP 3: conv set 3           ####
####     in: 32 x 64 x 64         ####
####    out: 4 x 8 x 128          ####
######################################

#### Left Leg  #######################
layer {
  name: "conv3_L"
  type: "Convolution"
  bottom: "pool2_L"
  top: "conv3_L"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_L"
  type: "ReLU"
  bottom: "conv3_L"
  top: "conv3_L"
}
layer {
  name: "scale3_L"
  type: "Scale"
  bottom: "conv3_L"
  top: "conv3_L"
  scale_param {
    bias_term: true
  }
}
#layer {
#  name: "norm3_L"
#  type: "LRN"
#  bottom: "conv3_L"
#  top: "conv3_L"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
#layer {
#  name: "conv3b_L"
#  type: "Convolution"
#  bottom: "conv3_L"
#  top: "conv3b_L"
#  param {
#    name: "conv3b_w"
#    lr_mult: 1
#  }
#  param {
#    name: "conv3b_b"
#    lr_mult: 2
#  }
#  convolution_param {
#    num_output: 64
#    kernel_size: 5
#    pad: 2
#    stride: 1
#    weight_filler {
#      type: "xavier"
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "relu3b_L"
#  type: "ReLU"
#  bottom: "conv3b_L"
#  top: "conv3b_L"
#}
#layer {
#  name: "norm3b_L"
#  type: "LRN"
#  bottom: "conv3b_L"
#  top: "conv3b_L"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "pool3_L"
  type: "Pooling"
#  bottom: "conv3b_L"
  bottom: "conv3_L"
  top: "pool3_L"
  pooling_param {
    pool: MAX
    kernel_size: 8
    stride: 8
  }
}

#### Right Leg #######################
layer {
  name: "conv3_R"
  type: "Convolution"
  bottom: "pool2_R"
  top: "conv3_R"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 7
    pad: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_R"
  type: "ReLU"
  bottom: "conv3_R"
  top: "conv3_R"
}
layer {
  name: "scale3_R"
  type: "Scale"
  bottom: "conv3_R"
  top: "conv3_R"
  scale_param {
    bias_term: true
  }
}
#layer {
#  name: "norm3_R"
#  type: "LRN"
#  bottom: "conv3_R"
#  top: "conv3_R"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
#layer {
#  name: "conv3b_R"
#  type: "Convolution"
#  bottom: "conv3_R"
#  top: "conv3b_R"
#  param {
#    name: "conv3b_w"
#    lr_mult: 1
#  }
#  param {
#    name: "conv3b_b"
#    lr_mult: 2
#  }
#  convolution_param {
#    num_output: 64
#    kernel_size: 5
#    pad: 2
#    stride: 1
#    weight_filler {
#      type: "xavier"
#    }
#    bias_filler {
#      type: "constant"
#    }
#  }
#}
#layer {
#  name: "relu3b_R"
#  type: "ReLU"
#  bottom: "conv3b_R"
#  top: "conv3b_R"
#}
#layer {
#  name: "norm3b_R"
#  type: "LRN"
#  bottom: "conv3b_R"
#  top: "conv3b_R"
#  lrn_param {
#    local_size: 5
#    alpha: 0.25
#    beta: 0.75
#    norm_region: WITHIN_CHANNEL
#  }
#}
layer {
  name: "pool3_R"
  type: "Pooling"
  bottom: "conv3_R"
#  bottom: "conv3b_R"
  top: "pool3_R"
  pooling_param {
    pool: MAX
    kernel_size: 8
    stride: 8
  }
}


# ######################################
# #### STEP 4: full-conn w/ conv    ####
# ####    out: 16 x 32 x 64         ####
# ######################################
# 
# #### Left Leg  #######################
# layer {
#   name: "fc4_L"
#   type: "InnerProduct"
#   bottom: "pool3_L"
#   top: "fc4_L"
#   param {
#     name: "fc4_w"
#     lr_mult: 1
#   }
#   param {
#     name: "fc4_b"
#     lr_mult: 2
#   }
#   inner_product_param {
#     num_output: 4096
#     weight_filler {
#       type: "xavier"
#     }
#     bias_filler {
#       type: "constant"
#     }
#   }
# }
# layer {
#   name: "relu4_L"
#   type: "ReLU"
#   bottom: "fc4_L"
#   top: "fc4_L"
# }
# layer {
#   name: "make2d4_L"
#   type: "Reshape"
#   bottom: "fc4_L"
#   top: "reshape4_L"
#   reshape_param {
#     shape {
#       dim: 0
#       dim: 8
#       dim: 16
#       dim: 32
#     }
#   }
# }
# layer {
#   name: "scale4_L"
#   type: "Scale"
#   bottom: "reshape4_L"
#   top: "reshape4_L"
#   scale_param {
#     bias_term: true
#   }
# }
# #layer {
# #  name: "drop4_L"
# #  type: "Dropout"
# #  bottom: "reshape4_L"
# #  top: "reshape4_L"
# #  dropout_param {
# #    dropout_ratio: 0.3
# #  }
# #}
# layer {
#   name: "pool4_L"
#   type: "Pooling"
#   bottom: "reshape4_L"
#   top: "pool4_L"
#   pooling_param {
#     pool: MAX
#     kernel_size: 2
#     stride: 2
#   }
# }
# layer {
#   name: "conv4_L"
#   type: "Convolution"
#   bottom: "pool4_L"
#   top: "conv4_L"
#   param {
#     name: "conv4_w"
#     lr_mult: 1
#   }
#   param {
#     name: "conv4_b"
#     lr_mult: 2
#   }
#   convolution_param {
#     num_output: 64
#     kernel_size: 5
#     pad: 2
#     stride: 1
#     weight_filler {
#       type: "xavier"
#     }
#     bias_filler {
#       type: "constant"
#     }
#   }
# }
# layer {
#   name: "relu4_L"
#   type: "ReLU"
#   bottom: "conv4_L"
#   top: "conv4_L"
# }
# #layer {
# #  name: "norm4_L"
# #  type: "LRN"
# #  bottom: "conv4_L"
# #  top: "conv4_L"
# #  lrn_param {
# #    local_size: 5
# #    alpha: 0.25
# #    beta: 0.75
# #    norm_region: WITHIN_CHANNEL
# #  }
# #}
# 
# #### Right Leg #######################
# layer {
#   name: "fc4_R"
#   type: "InnerProduct"
#   bottom: "pool3_R"
#   top: "fc4_R"
#   param {
#     name: "fc4_w"
#     lr_mult: 1
#   }
#   param {
#     name: "fc4_b"
#     lr_mult: 2
#   }
#   inner_product_param {
#     num_output: 4096
#     weight_filler {
#       type: "xavier"
#     }
#     bias_filler {
#       type: "constant"
#     }
#   }
# }
# layer {
#   name: "relu4_R"
#   type: "ReLU"
#   bottom: "fc4_R"
#   top: "fc4_R"
# }
# layer {
#   name: "make2d4_R"
#   type: "Reshape"
#   bottom: "fc4_R"
#   top: "reshape4_R"
#   reshape_param {
#     shape {
#       dim: 0
#       dim: 8
#       dim: 16
#       dim: 32
#     }
#   }
# }
# layer {
#   name: "scale4_R"
#   type: "Scale"
#   bottom: "reshape4_R"
#   top: "reshape4_R"
#   scale_param {
#     bias_term: true
#   }
# }
# #layer {
# #  name: "drop4_R"
# #  type: "Dropout"
# #  bottom: "reshape4_R"
# #  top: "reshape4_R"
# #  dropout_param {
# #    dropout_ratio: 0.3
# #  }
# #}
# layer {
#   name: "pool4_R"
#   type: "Pooling"
#   bottom: "reshape4_R"
#   top: "pool4_R"
#   pooling_param {
#     pool: MAX
#     kernel_size: 2
#     stride: 2
#   }
# }
# layer {
#   name: "conv4_R"
#   type: "Convolution"
#   bottom: "pool4_R"
#   top: "conv4_R"
#   param {
#     name: "conv4_w"
#     lr_mult: 1
#   }
#   param {
#     name: "conv4_b"
#     lr_mult: 2
#   }
#   convolution_param {
#     num_output: 64
#     kernel_size: 5
#     pad: 2
#     stride: 1
#     weight_filler {
#       type: "xavier"
#     }
#     bias_filler {
#       type: "constant"
#     }
#   }
# }
# layer {
#   name: "relu4_R"
#   type: "ReLU"
#   bottom: "conv4_R"
#   top: "conv4_R"
# }
# #layer {
# #  name: "norm4_R"
# #  type: "LRN"
# #  bottom: "conv4_R"
# #  top: "conv4_R"
# #  lrn_param {
# #    local_size: 5
# #    alpha: 0.25
# #    beta: 0.75
# #    norm_region: WITHIN_CHANNEL
# #  }
# #}


# ######################################
# #### STEP 5: fully-connecteds     ####
# ####    out: 16 x 32 x 32         ####
# ######################################
# 
# #### Left Leg  #######################
# layer {
#   name: "fc5_L"
#   type: "InnerProduct"
#   bottom: "conv4_L"
#   top: "fc5_L"
#   inner_product_param {
#     num_output: 4096
#     weight_filler {
#       type: "xavier"
#     }
#     bias_filler {
#       type: "constant"
#     }
#   }
# }
# layer {
#   name: "make2d5_L"
#   type: "Reshape"
#   bottom: "fc5_L"
#   top: "reshape5_L"
#   reshape_param {
#     shape {
#       dim: 0
#       dim: 8
#       dim: 16
#       dim: 32
#     }
#   }
# }
# #layer {
# #  name: "drop5_L"
# #  type: "Dropout"
# #  bottom: "reshape5_L"
# #  top: "reshape5_L"
# #  dropout_param {
# #    dropout_ratio: 0.3
# #  }
# #}
# 
# #### Right Leg #######################
# layer {
#   name: "fc5_R"
#   type: "InnerProduct"
#   bottom: "conv4_R"
#   top: "fc5_R"
#   inner_product_param {
#     num_output: 4096
#     weight_filler {
#       type: "xavier"
#     }
#     bias_filler {
#       type: "constant"
#     }
#   }
# }
# layer {
#   name: "make2d5_R"
#   type: "Reshape"
#   bottom: "fc5_R"
#   top: "reshape5_R"
#   reshape_param {
#     shape {
#       dim: 0
#       dim: 8
#       dim: 16
#       dim: 32
#     }
#   }
# }
# #layer {
# #  name: "drop5_R"
# #  type: "Dropout"
# #  bottom: "reshape5_R"
# #  top: "reshape5_R"
# #  dropout_param {
# #    dropout_ratio: 0.3
# #  }
# #}


######################################
#### STEP 6: join R & L legs      ####
####    out: 4 x 8 x 128 x 2      ####
####    out: 64 x 128 x 1         ####
######################################
layer {
  name: "joint_concat"
  type: "Concat"
#  bottom: "reshape5_L"
#  bottom: "reshape5_R"
  bottom: "pool3_L"
  bottom: "pool3_R"
  top: "joint_concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "joint_fc"
  type: "InnerProduct"
  bottom: "joint_concat"
  top: "joint_fc"
  param {
    name: "jfc_w"
    lr_mult: 1
  }
  param {
    name: "jfc_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8192
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "joint_make2d"
  type: "Reshape"
  bottom: "joint_fc"
  top: "joint_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 64
      dim: 128
    }
  }
}
layer {
  name: "joint_scale"
  type: "Scale"
  bottom: "joint_reshape"
  top: "joint_reshape"
  scale_param {
    bias_term: true
  }
}
#layer {
#  name: "joint_ups32"
#  type: "Deconvolution"
#  bottom: "joint_reshape"
#  top: "joint_upsamp"
#  convolution_param{
#    kernel_size: 4
#    stride: 2
#    num_output: 1
#    group: 1
#    pad: 1
#    weight_filler: {
#      type: "bilinear"
#    }
#    bias_term: false
#  }
#  param {
#     lr_mult: 0
#    decay_mult: 0
#  }
#}


######################################
#### STEP 7-8 alt: dwnsamp & loss ####
####    out: 1                    ####
######################################
layer {
  name: "pool1_GT"
  type: "Pooling"
  bottom: "GT_data"
  top: "pool1_GT"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "E_dn_loss"
  type: "EuclideanLoss"
  bottom: "joint_reshape"
  bottom: "pool1_GT"
  top: "Euclid_ls"
  loss_weight: 0
}


######################################
#### STEP 10: final loss          ####
####    out: 1                    ####
######################################

#### Convert ground truth layer ####
####  into 32 x 64
layer {
  name: "pool10_GT"
  type: "Pooling"
  bottom: "GT_data"
  top: "pool10_GT"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}

#### Convert concatenated layer ####
####  into 32 x 64
layer {
  name: "jfc10"
  type: "InnerProduct"
  bottom: "joint_concat"
  top: "jfc10"
  param {
    name: "jfc10_w"
    lr_mult: 1
  }
  param {
    name: "jfc10_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "j2d10"
  type: "Reshape"
  bottom: "jfc10"
  top: "j2d10"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: 32
      dim: 64
    }
  }
}
# #### Saturate output values ####
# layer {
#   name: "sigmoid10"
#   type: "Sigmoid"
#   bottom: "j2d10"
#   top: "sat_j2d10"
# }
# layer {
#   name: "jscale10"
#   type: "Scale"
#   bottom: "sat_j2d10"
#   top: "sat_j2d10"
#   scale_param {
#     bias_term: true
#   }
# }

#### Ensure positive values ####
layer {
  name: "relu10_R"
  type: "ReLU"
  bottom: "j2d10"
  top: "j2d10"
}
layer {
  name: "jscale10"
  type: "Scale"
  bottom: "j2d10"
  top: "j2d10"
  scale_param {
    bias_term: true
  }
}

#### Define Negative One ####
layer {
  name: "val_negone"
  type: "DummyData"
  top: "val_negone"
  dummy_data_param {
    shape {
      dim: 4    # batch size
      dim: 1
      dim: 32
      dim: 64
    }
    data_filler {
      type: "constant"
      value: -1
    }
  }
}

#### Define Gamma ####
layer {
  name: "val_gamma1"
  type: "DummyData"
  top: "val_gamma1"
  dummy_data_param {
    shape {
      dim: 4    # batch size
      dim: 1
      dim: 32
      dim: 64
    }
    data_filler {
      type: "constant"
      value: 0.5
    }
  }
}
layer {
  name: "inv_gamma"
  type: "Eltwise"
  bottom: "val_negone"
  bottom: "val_gamma1"
  top: "inv_gamma"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "val_gamma2"
  type: "Eltwise"
  bottom: "val_negone"
  bottom: "inv_gamma"
  top: "val_gamma2"
  eltwise_param {
    operation: PROD
  }
}


#### Invert Estimate ####
layer {
  name: "inv_estimate"
  type: "Eltwise"
  bottom: "val_negone"
  bottom: "j2d10"
#  bottom: "sat_j2d10"
  top: "inv_estimate"
  eltwise_param {
    operation: PROD
  }
}

#### Loss Part One ####
layer {
  name: "avg_estimate"
  type: "Pooling"
  bottom: "j2d10"
#  bottom: "sat_j2d10"
  top: "avg_estimate"
  pooling_param {
    pool: AVE
    kernel_size: 5
    stride: 1
    pad: 2
  }
}
layer {
  name: "dist_neighb"
  type: "Eltwise"
  bottom: "inv_estimate"
  bottom: "avg_estimate"
  top: "dist_neighb"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dist_n_2"
  type: "Power"
  bottom: "dist_neighb"
  top: "dist_n_2"
  power_param {
    power: 2
    scale: 1
    shift: 0
  }
}
layer {
  name: "loss_pt1"
  type: "Eltwise"
  bottom: "dist_n_2"
  bottom: "val_gamma1"
  top: "loss_pt1"
  eltwise_param {
    operation: PROD
  }
}

#### Loss Part Two ####
layer {
  name: "dist_truth"
  type: "Eltwise"
  bottom: "inv_estimate"
  bottom: "pool10_GT"
  top: "dist_truth"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dist_t_2"
  type: "Power"
  bottom: "dist_truth"
  top: "dist_t_2"
  power_param {
    power: 2
    scale: 1
    shift: 0
  }
}
layer {
  name: "loss_pt2"
  type: "Eltwise"
  bottom: "dist_t_2"
  bottom: "val_gamma2"
  top: "loss_pt2"
  eltwise_param {
    operation: PROD
  }
}

#### Final Loss ####
layer {
  name: "loss_combine"
  type: "Eltwise"
  bottom: "loss_pt2"
  bottom: "loss_pt1"
  top: "loss_combine"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "loss_final"
  type: "InnerProduct"
  bottom: "loss_combine"
  top: "loss"
  loss_weight: 1
  param {
    name: "lsv_w"
    lr_mult: 0
    decay_mult: 0
  }
  param {
    name: "lsv_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


######################################
#### STEP 11: upsample for disp   ####
####    out: 128 x 256            ####
######################################

#### avg pool down to 16x32       ####
#layer {
#  name: "pool11_est"
#  type: "Pooling"
#  bottom: "j2d10"
#  top: "pool11_est"
#  pooling_param {
#    pool: MAX
#    kernel_size: 2
#    stride: 2
#  }
#}
layer {
  name: "final_ups"
  type: "Deconvolution"
#  bottom: "pool11_est"
  bottom: "j2d10"
#  bottom: "sat_j2d10"
  top: "final_ups"
  convolution_param{
    kernel_size: 16
    stride: 8
    num_output: 1
    group: 1
    pad: 4
    weight_filler: {
      type: "bilinear"
    }
    bias_term: false
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "stfu_final"
  type: "Silence"
  bottom: "final_ups"
}

layer {
  name: "smoothed_out"
  type: "Pooling"
  bottom: "j2d10"
  top: "smoothed_out"
  pooling_param {
    pool: AVE
    kernel_size: 5
    stride: 1
    pad: 2
#    bias_term: false
  }
#  param {
#    lr_mult: 0
#    decay_mult: 0
#  }
}
layer {
  name: "stfu_smoothed"
  type: "Silence"
  bottom: "smoothed_out"
}

